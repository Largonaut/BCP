#!/usr/bin/env python3
"""
context_searcher.py - Search and navigate archived Claude Code session files.

Part of the Better Compaction Protocol. Provides prepared search tools for
navigating context_archive/ directories generated by context_preserver.py.

Location: F:\\claude_tools\\context_searcher.py
Usage:
    python F:/claude_tools/context_searcher.py search <query>
    python F:/claude_tools/context_searcher.py topics [--list] [<topic>]
    python F:/claude_tools/context_searcher.py timeline [--after DATE] [--before DATE]
    python F:/claude_tools/context_searcher.py session <id-or-date> [--turns N-M]
    python F:/claude_tools/context_searcher.py turns <file> [--role user|claude] [--contains KEYWORD]
    python F:/claude_tools/context_searcher.py semantic <char> | --list
"""

import argparse
import io
import os
import re
import sys
from pathlib import Path

# Force UTF-8 output on Windows to handle Unicode in session content
if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
if sys.stderr.encoding != 'utf-8':
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')


# --- Markdown parsing utilities ---

def find_archive_dir(archive_path: str = None) -> Path:
    """Locate the context_archive directory."""
    if archive_path:
        p = Path(archive_path)
        if p.is_dir():
            return p
        raise FileNotFoundError(f"Archive directory not found: {archive_path}")
    # Default: look for context_archive/ under cwd
    candidate = Path(os.getcwd()) / "context_archive"
    if candidate.is_dir():
        return candidate
    raise FileNotFoundError(
        f"No context_archive/ found in {os.getcwd()}\n"
        f"Use --archive-path to specify the archive directory."
    )


def resolve_session_file(archive_dir: Path, filename: str) -> Path:
    """Resolve a session file, preferring highest enrichment version."""
    # If they passed a full filename and it exists, use it
    candidate = archive_dir / filename
    if candidate.exists():
        return candidate
    # Try to find the best enriched version by identity
    if filename.endswith(".md"):
        identity = get_session_identity(filename)
        best = None
        best_version = -1
        for f in archive_dir.glob("session_*.md"):
            if get_session_identity(f.name) == identity:
                v = get_enrichment_version(f.name)
                if v > best_version:
                    best = f
                    best_version = v
        if best:
            return best
    raise FileNotFoundError(f"Session file not found: {filename}")


def get_enrichment_version(filename: str) -> int:
    """Extract enrichment version number from filename.

    .md = 0 (not enriched), .enriched.md = 1, .enriched2.md = 2, etc.
    Backward compatible: unnumbered .enriched.md is implicitly v1.
    """
    if ".enriched" not in filename:
        return 0
    m = re.search(r'\.enriched(\d*)\.md$', filename)
    if not m:
        return 0
    return int(m.group(1)) if m.group(1) else 1


def get_session_identity(filename: str) -> str:
    """Extract identity portion for dedup (strips extension + semantic tag).

    Examples:
        session_2026-02-15_04c9392f.md -> session_2026-02-15_04c9392f
        session_2026-02-15_04c9392f~$L.enriched.md -> session_2026-02-15_04c9392f
        session_2026-02-15_04c9392f~$L.enriched2.md -> session_2026-02-15_04c9392f
        session_2026-02-15_04c9392f_b~XYZ.md -> session_2026-02-15_04c9392f_b
    """
    # Strip versioned enrichment extensions (.enriched.md, .enriched2.md, etc.)
    name = re.sub(r'\.enriched\d*\.md$', '', filename)
    if name == filename:
        # No enrichment extension found — strip plain .md
        name = filename.replace(".md", "")
    if "~" in name:
        name = name.split("~")[0]
    return name


def get_semantic_tag(filename: str) -> str:
    """Extract the semantic tag portion from a filename (after ~ separator).

    Returns empty string if no semantic tag present.
    """
    name = re.sub(r'\.enriched\d*\.md$', '', filename)
    if name == filename:
        name = filename.replace(".md", "")
    if "~" in name:
        return name.split("~", 1)[1]
    return ""


def list_session_files(archive_dir: Path) -> list:
    """List all session files, preferring highest enrichment version.
    Returns list of Path objects sorted by filename (chronological by date prefix).
    Deduplicates by session identity (ignoring semantic tags and enrichment extensions).
    Preference: highest enrichment version wins, then tagged over untagged.
    """
    files = {}  # identity -> best_path
    for f in archive_dir.glob("session_*.md"):
        if f.name == "index.md":
            continue
        identity = get_session_identity(f.name)
        if identity not in files:
            files[identity] = f
        else:
            current = files[identity]
            cur_version = get_enrichment_version(current.name)
            new_version = get_enrichment_version(f.name)
            # Higher enrichment version always wins
            if new_version > cur_version:
                files[identity] = f
            elif new_version == cur_version:
                # Same version: prefer tagged over untagged
                cur_tagged = "~" in current.name
                new_tagged = "~" in f.name
                if new_tagged and not cur_tagged:
                    files[identity] = f
    return sorted(files.values(), key=lambda p: p.name)


def parse_session_header(filepath: Path) -> dict:
    """Parse the metadata header from a session .md file."""
    meta = {"filepath": filepath, "filename": filepath.name}
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            header_text = f.read(3000)
    except (OSError, UnicodeDecodeError):
        return meta

    # Title line: # Session: 2026-02-15 | ProjectName
    m = re.search(r'^# Session:\s*(\S+)\s*\|\s*(.+)$', header_text, re.MULTILINE)
    if m:
        meta["date"] = m.group(1)
        meta["project"] = m.group(2).strip()

    # Key-value pairs: **Key**: value
    for key_match in re.finditer(r'\*\*(\w[\w\s]*?)\*\*:\s*(.+?)(?:\s\s$|\n)', header_text, re.MULTILINE):
        key = key_match.group(1).strip().lower().replace(" ", "_")
        value = key_match.group(2).strip().rstrip("  ")
        meta[key] = value

    # Parse turns count as int
    if "turns" in meta:
        try:
            meta["turns"] = int(meta["turns"])
        except ValueError:
            pass

    return meta


def parse_turns(filepath: Path) -> list:
    """Parse individual turns from a session .md file.
    Returns list of dicts: {number, role, time, content, is_tool, is_thinking}
    """
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
    except (OSError, UnicodeDecodeError):
        return []

    turns = []
    # Split on turn headers: ## Turn N — Role [HH:MM:SS]
    turn_pattern = re.compile(
        r'^## Turn (\d+) — (User|Claude) \[(\S*)\]\s*$',
        re.MULTILINE
    )

    matches = list(turn_pattern.finditer(content))
    for i, match in enumerate(matches):
        start = match.end()
        end = matches[i + 1].start() if i + 1 < len(matches) else len(content)
        turn_content = content[start:end].strip()

        # Remove trailing --- separator
        turn_content = re.sub(r'\n---\s*$', '', turn_content).strip()

        # Check for tool use
        is_tool = "**Tool**:" in turn_content

        # Check for thinking block
        is_thinking = "<details><summary>Thinking</summary>" in turn_content

        # Strip thinking blocks for content display
        display_content = re.sub(
            r'<details><summary>Thinking</summary>.*?</details>',
            '', turn_content, flags=re.DOTALL
        ).strip()

        turns.append({
            "number": int(match.group(1)),
            "role": match.group(2).lower(),
            "time": match.group(3),
            "content": display_content,
            "full_content": turn_content,
            "is_tool": is_tool,
            "is_thinking": is_thinking,
        })

    return turns


# --- Subcommands ---

def cmd_search(args):
    """Full-text keyword search across all session files."""
    archive_dir = find_archive_dir(args.archive_path)
    session_files = list_session_files(archive_dir)
    query = args.query.lower()
    results = []

    for sf in session_files:
        meta = parse_session_header(sf)
        session_date = meta.get("date", "unknown")

        # Date filtering
        if args.after and session_date < args.after:
            continue
        if args.before and session_date > args.before:
            continue

        turns = parse_turns(sf)
        for turn in turns:
            # Role filtering
            if args.role and turn["role"] != args.role.lower():
                continue

            if query in turn["content"].lower():
                # Find the matching line(s)
                for line_num, line in enumerate(turn["content"].split('\n')):
                    if query in line.lower():
                        results.append({
                            "file": sf.name,
                            "date": session_date,
                            "turn": turn["number"],
                            "role": turn["role"],
                            "time": turn["time"],
                            "line": line.strip()[:150],
                        })

    if not results:
        print(f"No results for '{args.query}'")
        return 1

    # Apply limit
    limit = args.limit or 20
    shown = results[:limit]

    print(f"Found {len(results)} match(es) for '{args.query}':\n")
    for r in shown:
        print(f"  [{r['date']}] Turn {r['turn']} ({r['role']}) [{r['time']}] in {r['file']}")
        print(f"    {r['line']}")
        print()

    if len(results) > limit:
        print(f"  ... and {len(results) - limit} more (use --limit to see more)")
    return 0


def cmd_topics(args):
    """Topic-based navigation across sessions."""
    archive_dir = find_archive_dir(args.archive_path)
    session_files = list_session_files(archive_dir)

    # Collect topics from all session headers
    all_topics = {}  # topic -> list of session info

    for sf in session_files:
        meta = parse_session_header(sf)
        topics_str = meta.get("topics", "")
        if not topics_str:
            continue
        session_info = {
            "file": sf.name,
            "date": meta.get("date", "unknown"),
            "turns": meta.get("turns", "?"),
            "summary": meta.get("summary", ""),
        }
        for topic in [t.strip() for t in topics_str.split(",") if t.strip()]:
            if topic not in all_topics:
                all_topics[topic] = []
            all_topics[topic].append(session_info)

    if args.list_all:
        # List all topics with session counts
        if not all_topics:
            print("No topics found. Run context_preserver.py --enrich to generate topic metadata.")
            return 1

        print(f"Topics across {len(session_files)} session(s):\n")
        for topic in sorted(all_topics.keys(), key=lambda t: (-len(all_topics[t]), t.lower())):
            count = len(all_topics[topic])
            dates = ", ".join(s["date"] for s in all_topics[topic])
            print(f"  {topic} ({count} session{'s' if count > 1 else ''}): {dates}")
        return 0

    if args.topic:
        # Find sessions containing a specific topic (case-insensitive partial match)
        query = args.topic.lower()
        matches = []
        for topic, sessions in all_topics.items():
            if query in topic.lower():
                for s in sessions:
                    matches.append({"topic": topic, **s})

        if not matches:
            # Fallback: full-text search for the topic term
            print(f"No topic tag '{args.topic}' found in headers. Falling back to full-text search...\n")
            args.query = args.topic
            args.role = None
            args.after = None
            args.before = None
            args.limit = 10
            return cmd_search(args)

        print(f"Sessions matching topic '{args.topic}':\n")
        for m in matches:
            summary = m['summary'][:60] if m.get('summary') else ''
            print(f"  [{m['date']}] {m['turns']} turns — {summary}")
            print(f"    File: {m['file']}")
            print()
        return 0

    print("Usage: topics --list  OR  topics <topic_name>")
    return 1


def cmd_timeline(args):
    """Chronological session overview."""
    archive_dir = find_archive_dir(args.archive_path)
    session_files = list_session_files(archive_dir)

    if not session_files:
        print("No session files found.")
        return 1

    print(f"Timeline ({len(session_files)} session{'s' if len(session_files) > 1 else ''}):\n")

    for sf in session_files:
        meta = parse_session_header(sf)
        date = meta.get("date", "unknown")

        # Date filtering
        if args.after and date < args.after:
            continue
        if args.before and date > args.before:
            continue

        turns = meta.get("turns", "?")
        topics = meta.get("topics", "")[:50]
        summary = meta.get("summary", "")[:60]
        print(f"  {date} | {turns:>3} turns | {sf.name}")
        if topics:
            print(f"    Topics: {topics}")
        if summary:
            print(f"    Summary: {summary}")
        print()

    return 0


def cmd_session(args):
    """Show session detail view."""
    archive_dir = find_archive_dir(args.archive_path)

    # Resolve session by ID fragment, date, or filename
    target = args.target
    session_file = None

    # Try direct filename match first
    for sf in list_session_files(archive_dir):
        if target in sf.name or target in sf.stem:
            session_file = sf
            break

    # Try date match
    if not session_file:
        for sf in list_session_files(archive_dir):
            meta = parse_session_header(sf)
            if meta.get("date", "") == target:
                session_file = sf
                break

    if not session_file:
        print(f"No session matching '{target}' found.")
        return 1

    meta = parse_session_header(session_file)
    turns = parse_turns(session_file)

    # Print header
    print(f"Session: {meta.get('date', 'unknown')} | {meta.get('project', '')}")
    print(f"  File: {session_file.name}")
    for key in ['session_id', 'turns', 'model', 'summary', 'topics', 'tools_used']:
        if key in meta:
            print(f"  {key.replace('_', ' ').title()}: {meta[key]}")
    print()

    # Parse turn range if specified
    turn_start, turn_end = 1, len(turns)
    if args.turns:
        parts = args.turns.split("-")
        try:
            turn_start = int(parts[0])
            turn_end = int(parts[1]) if len(parts) > 1 else turn_start
        except ValueError:
            print(f"Invalid turn range: {args.turns} (use N or N-M)")
            return 1

    # Print turns
    for turn in turns:
        if turn["number"] < turn_start or turn["number"] > turn_end:
            continue

        marker = ""
        if turn["is_tool"]:
            marker = " [tool]"
        elif turn["is_thinking"]:
            marker = " [thinking]"

        if args.full:
            print(f"## Turn {turn['number']} — {turn['role'].title()} [{turn['time']}]{marker}")
            print()
            print(turn["content"])
            print()
            print("---")
            print()
        else:
            # Summary: one line per turn
            preview = turn["content"].split('\n')[0][:80] if turn["content"] else ""
            print(f"  Turn {turn['number']:>3} | {turn['role']:>6} [{turn['time']}]{marker}: {preview}")

    return 0


def cmd_turns(args):
    """Turn-level filtering within a session file."""
    archive_dir = find_archive_dir(args.archive_path)

    try:
        session_file = resolve_session_file(archive_dir, args.file)
    except FileNotFoundError as e:
        # Try partial match
        for sf in list_session_files(archive_dir):
            if args.file in sf.name:
                session_file = sf
                break
        else:
            print(f"Session file not found: {args.file}")
            return 1

    turns = parse_turns(session_file)
    if not turns:
        print(f"No turns found in {session_file.name}")
        return 1

    results = []
    for turn in turns:
        # Role filter
        if args.role and turn["role"] != args.role.lower():
            continue

        # Tools-only filter
        if args.tools and not turn["is_tool"]:
            continue

        # Time filters
        if args.after_time and turn["time"] < args.after_time:
            continue
        if args.before_time and turn["time"] > args.before_time:
            continue

        # Keyword filter
        if args.contains and args.contains.lower() not in turn["content"].lower():
            continue

        results.append(turn)

    if not results:
        print("No turns match the given filters.")
        return 1

    print(f"Matched {len(results)} turn(s) in {session_file.name}:\n")
    for turn in results:
        marker = " [tool]" if turn["is_tool"] else ""
        print(f"## Turn {turn['number']} — {turn['role'].title()} [{turn['time']}]{marker}")
        print()
        print(turn["content"])
        print()
        print("---")
        print()

    return 0


def cmd_semantic(args):
    """Search sessions by semantic tag characters."""
    import json

    archive_dir = find_archive_dir(args.archive_path)

    # Load semantic map for display
    map_path = Path(__file__).parent / "semantic_map.json"
    mappings = {}
    if map_path.exists():
        try:
            with open(map_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            mappings = data.get("mappings", {})
        except (json.JSONDecodeError, OSError):
            pass

    if args.list_map:
        # Show the full mapping table
        if not mappings:
            print("No semantic map found.")
            return 1
        print(f"Semantic map ({len(mappings)} mappings):")
        for char in sorted(mappings, key=ord):
            print(f"  {char} -> {mappings[char]}")
        return 0

    query_char = args.char
    if not query_char:
        print("Usage: semantic <char> or semantic --list")
        return 1

    # Search for files with this character in their semantic tag
    matching = []
    for sf in list_session_files(archive_dir):
        tag = get_semantic_tag(sf.name)
        if query_char in tag:
            matching.append(sf)

    if not matching:
        topic_name = mappings.get(query_char, "(unknown topic)")
        print(f"No sessions found with semantic tag '{query_char}' ({topic_name})")
        return 0

    topic_name = mappings.get(query_char, "(unknown topic)")
    print(f"Sessions with '{query_char}' ({topic_name}): {len(matching)}")
    print()

    for sf in matching:
        tag = get_semantic_tag(sf.name)
        # Show full tag with all mappings
        tag_display = ", ".join(f"{c} ({mappings.get(c, '?')})" for c in tag)
        print(f"  {sf.name}")
        print(f"    Tags: {tag_display}")

        if args.deep:
            # Read file and find paragraph-level markers containing the query char
            try:
                with open(sf, "r", encoding="utf-8") as f:
                    lines = f.readlines()
            except OSError:
                print(f"    (could not read file)")
                print()
                continue

            current_turn = None
            for line in lines:
                line_stripped = line.rstrip("\n")
                # Track current turn header
                turn_match = re.match(r'^## (Turn \d+ — \S+ \[\S*\])\s*(\{.*\})?', line_stripped)
                if turn_match:
                    current_turn = turn_match.group(1)
                    turn_tag = turn_match.group(2) or ""
                    if query_char in turn_tag:
                        print(f"    {current_turn} {turn_tag}")
                    continue
                # Check paragraph markers: lines that are just {chars}
                para_match = re.match(r'^\{([^}]+)\}$', line_stripped)
                if para_match and current_turn:
                    marker_chars = para_match.group(1)
                    if query_char in marker_chars:
                        print(f"      {{{marker_chars}}}")

        print()

    return 0


# --- Main ---

def main():
    parser = argparse.ArgumentParser(
        description="Search and navigate archived Claude Code session files",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""Examples:
  %(prog)s search "DDSMRLV"                  Full-text keyword search
  %(prog)s search "compaction" --role user    Search only user messages
  %(prog)s topics --list                      List all extracted topics
  %(prog)s topics "Libraric"                  Find sessions about a topic
  %(prog)s timeline                           Show all sessions chronologically
  %(prog)s timeline --after 2026-02-01        Sessions after a date
  %(prog)s session 2026-02-15                 Session detail by date
  %(prog)s session 04c9392f --full            Full session content by ID
  %(prog)s turns session_2026-02-15_04c9392f.md --role user
  %(prog)s turns session_2026-02-15_04c9392f.md --contains "tool"
"""
    )
    parser.add_argument(
        "--archive-path",
        default=None,
        help="Path to context_archive/ directory (default: ./context_archive/)"
    )

    subparsers = parser.add_subparsers(dest="command", help="Search command")

    # search
    p_search = subparsers.add_parser("search", help="Full-text keyword search")
    p_search.add_argument("query", help="Search term")
    p_search.add_argument("--role", choices=["user", "claude"], help="Filter by speaker")
    p_search.add_argument("--after", help="Only sessions after this date (YYYY-MM-DD)")
    p_search.add_argument("--before", help="Only sessions before this date (YYYY-MM-DD)")
    p_search.add_argument("--limit", type=int, help="Max results to show (default: 20)")

    # topics
    p_topics = subparsers.add_parser("topics", help="Topic-based navigation")
    p_topics.add_argument("topic", nargs="?", help="Topic to search for")
    p_topics.add_argument("--list", dest="list_all", action="store_true", help="List all topics")

    # timeline
    p_timeline = subparsers.add_parser("timeline", help="Chronological session overview")
    p_timeline.add_argument("--after", help="Only sessions after this date (YYYY-MM-DD)")
    p_timeline.add_argument("--before", help="Only sessions before this date (YYYY-MM-DD)")

    # session
    p_session = subparsers.add_parser("session", help="Show session detail")
    p_session.add_argument("target", help="Session ID fragment, date, or filename")
    p_session.add_argument("--full", action="store_true", help="Show full turn content")
    p_session.add_argument("--turns", help="Turn range to show (e.g., 1-5 or 3)")

    # turns
    p_turns = subparsers.add_parser("turns", help="Turn-level filtering")
    p_turns.add_argument("file", help="Session filename or partial match")
    p_turns.add_argument("--role", choices=["user", "claude"], help="Filter by speaker")
    p_turns.add_argument("--tools", action="store_true", help="Only tool use turns")
    p_turns.add_argument("--after", dest="after_time", help="After this time (HH:MM)")
    p_turns.add_argument("--before", dest="before_time", help="Before this time (HH:MM)")
    p_turns.add_argument("--contains", help="Keyword filter within turn content")

    p_semantic = subparsers.add_parser("semantic", help="Search by semantic tag character")
    p_semantic.add_argument("char", nargs="?", help="Semantic character to search for")
    p_semantic.add_argument("--list", dest="list_map", action="store_true",
                            help="Show the full semantic mapping table")
    p_semantic.add_argument("--deep", action="store_true",
                            help="Show paragraph-level locations within files")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    try:
        if args.command == "search":
            sys.exit(cmd_search(args))
        elif args.command == "topics":
            sys.exit(cmd_topics(args))
        elif args.command == "timeline":
            sys.exit(cmd_timeline(args))
        elif args.command == "session":
            sys.exit(cmd_session(args))
        elif args.command == "turns":
            sys.exit(cmd_turns(args))
        elif args.command == "semantic":
            sys.exit(cmd_semantic(args))
    except FileNotFoundError as e:
        print(f"ERROR: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
